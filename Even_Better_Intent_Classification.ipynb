{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import urllib\n",
    "import numpy as np\n",
    "import json\n",
    "import gensim\n",
    "import gensim.downloader\n",
    "import re \n",
    "\n",
    "# Download word vectorizer\n",
    "vectors = gensim.downloader.load('glove-wiki-gigaword-50')\n",
    "\n",
    "\n",
    "# Download data\n",
    "def get_response(url):\n",
    "    operUrl = urllib.request.urlopen(url)\n",
    "    if(operUrl.getcode()==200):\n",
    "        data = operUrl.read()\n",
    "    else:\n",
    "        print(\"Error receiving data\", operUrl.getcode())\n",
    "    return data\n",
    "\n",
    "data = get_response('https://raw.githubusercontent.com/clinc/oos-eval/master/data/data_full.json')\n",
    "\n",
    "\n",
    "# Load and combine data into train, val, and test sets\n",
    "json_data = json.loads(data)\n",
    "val = json_data['val']\n",
    "oos_val = json_data['oos_val']\n",
    "test = json_data['test']\n",
    "oos_test = json_data['oos_test']\n",
    "train = json_data['train']\n",
    "oos_train = json_data['oos_train']\n",
    "\n",
    "\n",
    "for i in oos_train:\n",
    "    train.append(i) \n",
    "\n",
    "for i in oos_val:\n",
    "    val.append(i) \n",
    "\n",
    "for i in oos_test:\n",
    "    test.append(i) \n",
    "\n",
    "### Strip data of symbols and convert to lists of strings    \n",
    "# Create regex pattern\n",
    "pattern = re.compile('[^\\w\\s]')\n",
    "\n",
    "# Define function to apply regex pattern over each dataset\n",
    "def string_separation(data):\n",
    "    return [pattern.sub('', data[i][0]).split(\" \") \\\n",
    "     for i, j in enumerate(data)]\n",
    "\n",
    "# Apply function to each dataset\n",
    "train_separated_values = string_separation(train)\n",
    "val_separated_values = string_separation(val)\n",
    "test_separated_values = string_separation(test)\n",
    "\n",
    "\n",
    "### vectorize each value using word2vec\n",
    "\n",
    "# Create function that checks if a string can be vectorized against the vectorizer\n",
    "# If it can, vectorize it, otherwise return a 0.0 array of equal size\n",
    "def get_vector(string):\n",
    "    try: \n",
    "        value = vectors.get_vector(string)\n",
    "        return value\n",
    "    except:\n",
    "        return np.array([0.0] * 50)\n",
    "    \n",
    "# Create a function that applies the get_vector function across a list of values\n",
    "def convert_to_vectors(series):\n",
    "    new_series = []\n",
    "\n",
    "    for i in series:\n",
    "        if i == '':\n",
    "            pass\n",
    "        else:\n",
    "            new_series.append(get_vector(i))\n",
    "            \n",
    "    return new_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that applies convert_to_vectors across an entire dataset\n",
    "def vectorize_samples(data):\n",
    "    return [convert_to_vectors(data[i]) for i, j in enumerate(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize each dataset\n",
    "train_X_arrays = vectorize_samples(train_separated_values)\n",
    "val_X_arrays = vectorize_samples(val_separated_values)\n",
    "test_X_arrays = vectorize_samples(test_separated_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since values are being assigned to Tensors establish the storage location by checking for GPU\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Establish padding length (Could have been as low as 30 given data set 50 was chosen to increase usability)\n",
    "pad_length = 50\n",
    "\n",
    "# Create an empty array to be used for padding values\n",
    "pad_value = np.array([0.0] * 50, dtype=np.float32)\n",
    "\n",
    "# Define function that takes a list, pad_length, and pad_value to create a new array of values with 0 padded values up to the pad_length\n",
    "def adjust_padding(some_list, pad_length=pad_length, pad_value=pad_value):\n",
    "    some_list = list(some_list)\n",
    "    while len(some_list) < pad_length:\n",
    "        some_list.append(pad_value)\n",
    "    return np.array(some_list)\n",
    "\n",
    "# Apply the function over each dataset\n",
    "train_padded      = [adjust_padding(i) for i in train_X_arrays]\n",
    "val_padded        = [adjust_padding(val_X_arrays[i]) for i, j in enumerate(val_X_arrays)]\n",
    "test_padded       = [adjust_padding(test_X_arrays[i]) for i, j in enumerate(test_X_arrays)]\n",
    "\n",
    "# Convert arrays to tensors to feed model\n",
    "\n",
    "train_set         = torch.tensor(train_padded).reshape((15100,1,50,50)).float().to(device)\n",
    "val_set           = torch.tensor(val_padded).reshape((3100,1,50,50)).float().to(device)\n",
    "test_set          = torch.tensor(test_padded).reshape((5500,1,50,50)).float().to(device)\n",
    "\n",
    "# Create tensors of answers\n",
    "\n",
    "train_answer      = [j[1] for i, j in enumerate(train)]\n",
    "val_answer        = [j[1] for i, j in enumerate(val)]\n",
    "test_answer       = [j[1] for i, j in enumerate(test)]\n",
    "\n",
    "### Create an index to train against\n",
    "\n",
    "# Create dictionary map of each unique answer type\n",
    "chosen_dict = {j: i for i, j in enumerate(list(set([train[i][1] for i, j in enumerate(train)])))}\n",
    "\n",
    "# Use dictionary to consistently label answer data\n",
    "for item in chosen_dict.keys():\n",
    "    for i, j in enumerate(train_answer):\n",
    "        if item == j:\n",
    "            train_answer[i] = chosen_dict[item]\n",
    "    for i, j in enumerate(val_answer):\n",
    "        if item == j:\n",
    "            val_answer[i] = chosen_dict[item]\n",
    "    for i, j in enumerate(test_answer):\n",
    "        if item == j:\n",
    "            test_answer[i] = chosen_dict[item]\n",
    "\n",
    "# Convert labeled data into tensors\n",
    "train_answers = torch.tensor(train_answer).to(device)\n",
    "val_answers = torch.tensor(val_answer).to(device)\n",
    "test_answers = torch.tensor(test_answer).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierModel2(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(ClassifierModel2, self).__init__()\n",
    "        \n",
    "        # Add super_wide layer\n",
    "        \n",
    "        self.super_wide = nn.Conv2d(1, 128, (7, 50))\n",
    "        self.wide_conv = nn.Conv2d(1, 32, (5, 50))\n",
    "        self.narrow_conv1 = nn.Conv2d(1, 32, (3, 50))\n",
    "        self.narrow_conv2 = nn.Conv1d(32, 32, (3))\n",
    "        self.conv2 = nn.Conv1d(64, 128, (3))\n",
    "        # Add linear layer\n",
    "        self.linear1 = nn.Linear(256*44, 512)\n",
    "        self.linear2 = nn.Linear(512, 256)\n",
    "        self.linear3 = nn.Linear(256, 128)\n",
    "        self.probs_pre = nn.Linear(128, 151) # 151 output classes\n",
    "        self.probabilities = nn.Softmax(dim=1)\n",
    "        self.dropout = nn.Dropout(.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Use wide (5) and super_wide (7) word convolution to capture longer-term dependencies\n",
    "        a = F.elu(self.super_wide(x))\n",
    "        a = a.view(a.shape[0:3])\n",
    "        y = F.elu(self.wide_conv(x))\n",
    "        y = y.view(y.shape[0:3])\n",
    "        # Use short (3) word convolution to capture neighboring relationships\n",
    "        z = F.elu(self.narrow_conv1(x))\n",
    "        z = z.view(z.shape[0:3])\n",
    "        z = F.elu(self.narrow_conv2(z))\n",
    "        # Concatenate results\n",
    "        x = torch.cat((y, z), 1)\n",
    "        # Perform one additional convolution to evaluate the connection between dependencies\n",
    "        x = F.elu(self.conv2(x))\n",
    "        # Concatenate with 7 word results\n",
    "        x = torch.cat((x, a), 1)\n",
    "        # Pass to Feed Forward ANN to produce probabilities of each class\n",
    "        # Use dropout to reduce overfitting and assist model with training on un-seen data\n",
    "        x = x.view(-1, 256*44)\n",
    "        x = F.elu(self.dropout(self.linear1(x)))\n",
    "        x = F.elu(self.dropout(self.linear2(x)))\n",
    "        x = F.elu(self.dropout(self.linear3(x)))\n",
    "        x = self.probabilities(self.probs_pre(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:     5.0173\n",
      "Val Loss: 5.0171\n",
      "0.0% done\n",
      "Loss:     4.5777\n",
      "Val Loss: 4.6706\n",
      "1.0% done\n",
      "Loss:     4.5217\n",
      "Val Loss: 4.6390\n",
      "2.0% done\n",
      "Loss:     4.4621\n",
      "Val Loss: 4.5962\n",
      "3.0% done\n",
      "Loss:     4.4303\n",
      "Val Loss: 4.5708\n",
      "4.0% done\n",
      "Loss:     4.4116\n",
      "Val Loss: 4.5536\n",
      "5.0% done\n",
      "Loss:     4.3983\n",
      "Val Loss: 4.5495\n",
      "6.0% done\n",
      "Loss:     4.3810\n",
      "Val Loss: 4.5302\n",
      "7.0% done\n",
      "Loss:     4.3551\n",
      "Val Loss: 4.5142\n",
      "8.0% done\n",
      "Loss:     4.3256\n",
      "Val Loss: 4.4946\n",
      "9.0% done\n",
      "Loss:     4.3049\n",
      "Val Loss: 4.4866\n",
      "10.0% done\n",
      "Loss:     4.2865\n",
      "Val Loss: 4.4640\n",
      "11.0% done\n",
      "Loss:     4.2709\n",
      "Val Loss: 4.4488\n",
      "12.0% done\n",
      "Loss:     4.2387\n",
      "Val Loss: 4.4314\n",
      "13.0% done\n",
      "Loss:     4.2307\n",
      "Val Loss: 4.4215\n",
      "14.0% done\n",
      "Loss:     4.2111\n",
      "Val Loss: 4.4010\n",
      "15.0% done\n",
      "Loss:     4.2108\n",
      "Val Loss: 4.4005\n",
      "16.0% done\n",
      "Loss:     4.1975\n",
      "Val Loss: 4.3960\n",
      "17.0% done\n",
      "Loss:     4.1776\n",
      "Val Loss: 4.4029\n",
      "18.0% done\n",
      "Loss:     4.1712\n",
      "Val Loss: 4.3813\n",
      "19.0% done\n",
      "Loss:     4.1643\n",
      "Val Loss: 4.3744\n",
      "20.0% done\n",
      "Loss:     4.1581\n",
      "Val Loss: 4.3693\n",
      "21.0% done\n",
      "Loss:     4.1444\n",
      "Val Loss: 4.3601\n",
      "22.0% done\n",
      "Loss:     4.1379\n",
      "Val Loss: 4.3526\n",
      "23.0% done\n",
      "Loss:     4.1245\n",
      "Val Loss: 4.3419\n",
      "24.0% done\n",
      "Loss:     4.1244\n",
      "Val Loss: 4.3438\n",
      "25.0% done\n",
      "Loss:     4.1242\n",
      "Val Loss: 4.3364\n",
      "26.0% done\n",
      "Loss:     4.1181\n",
      "Val Loss: 4.3409\n",
      "27.0% done\n",
      "Loss:     4.1048\n",
      "Val Loss: 4.3285\n",
      "28.0% done\n",
      "Loss:     4.1046\n",
      "Val Loss: 4.3353\n",
      "29.0% done\n",
      "Loss:     4.0981\n",
      "Val Loss: 4.3269\n",
      "30.0% done\n",
      "Loss:     4.0980\n",
      "Val Loss: 4.3227\n",
      "31.0% done\n",
      "Loss:     4.0912\n",
      "Val Loss: 4.3201\n",
      "32.0% done\n",
      "Loss:     4.0913\n",
      "Val Loss: 4.3158\n",
      "33.0% done\n",
      "Loss:     4.0848\n",
      "Val Loss: 4.3201\n",
      "34.0% done\n",
      "Loss:     4.0847\n",
      "Val Loss: 4.3156\n",
      "35.0% done\n",
      "Loss:     4.0847\n",
      "Val Loss: 4.3121\n",
      "36.0% done\n",
      "Loss:     4.0781\n",
      "Val Loss: 4.3154\n",
      "37.0% done\n",
      "Loss:     4.0781\n",
      "Val Loss: 4.3066\n",
      "38.0% done\n",
      "Loss:     4.0715\n",
      "Val Loss: 4.3023\n",
      "39.0% done\n",
      "Loss:     4.0714\n",
      "Val Loss: 4.2996\n",
      "40.0% done\n",
      "Loss:     4.0649\n",
      "Val Loss: 4.3051\n",
      "41.0% done\n",
      "Loss:     4.0646\n",
      "Val Loss: 4.3033\n",
      "42.0% done\n",
      "Loss:     4.0580\n",
      "Val Loss: 4.2939\n",
      "43.0% done\n",
      "Loss:     4.0580\n",
      "Val Loss: 4.2956\n",
      "44.0% done\n",
      "Loss:     4.0578\n",
      "Val Loss: 4.2900\n",
      "45.0% done\n",
      "Loss:     4.0511\n",
      "Val Loss: 4.2901\n",
      "46.0% done\n",
      "Loss:     4.0511\n",
      "Val Loss: 4.2915\n",
      "47.0% done\n",
      "Loss:     4.0510\n",
      "Val Loss: 4.2871\n",
      "48.0% done\n",
      "Loss:     4.0512\n",
      "Val Loss: 4.2914\n",
      "49.0% done\n",
      "Loss:     4.0511\n",
      "Val Loss: 4.2856\n",
      "50.0% done\n",
      "Loss:     4.0448\n",
      "Val Loss: 4.2875\n",
      "51.0% done\n",
      "Loss:     4.0446\n",
      "Val Loss: 4.2840\n",
      "52.0% done\n",
      "Loss:     4.0444\n",
      "Val Loss: 4.2915\n",
      "53.0% done\n",
      "Loss:     4.0444\n",
      "Val Loss: 4.2796\n",
      "54.0% done\n",
      "Loss:     4.0444\n",
      "Val Loss: 4.2777\n",
      "55.0% done\n",
      "Loss:     4.0444\n",
      "Val Loss: 4.2793\n",
      "56.0% done\n",
      "Loss:     4.0442\n",
      "Val Loss: 4.2861\n",
      "57.0% done\n",
      "Loss:     4.0443\n",
      "Val Loss: 4.2766\n",
      "58.0% done\n",
      "Loss:     4.0443\n",
      "Val Loss: 4.2783\n",
      "59.0% done\n",
      "Loss:     4.0442\n",
      "Val Loss: 4.2798\n",
      "60.0% done\n",
      "Loss:     4.0442\n",
      "Val Loss: 4.2753\n",
      "61.0% done\n",
      "Loss:     4.0442\n",
      "Val Loss: 4.2827\n",
      "62.0% done\n",
      "Loss:     4.0441\n",
      "Val Loss: 4.2798\n",
      "63.0% done\n",
      "Loss:     4.0442\n",
      "Val Loss: 4.2865\n",
      "64.0% done\n",
      "Loss:     4.0382\n",
      "Val Loss: 4.2831\n",
      "65.0% done\n",
      "Loss:     4.0377\n",
      "Val Loss: 4.2796\n",
      "66.0% done\n",
      "Loss:     4.0376\n",
      "Val Loss: 4.2867\n",
      "67.0% done\n",
      "Loss:     4.0376\n",
      "Val Loss: 4.2789\n",
      "68.0% done\n",
      "Loss:     4.0311\n",
      "Val Loss: 4.2753\n",
      "69.0% done\n",
      "Loss:     4.0310\n",
      "Val Loss: 4.2728\n",
      "70.0% done\n",
      "Loss:     4.0311\n",
      "Val Loss: 4.2801\n",
      "71.0% done\n",
      "Loss:     4.0311\n",
      "Val Loss: 4.2775\n",
      "72.0% done\n",
      "Loss:     4.0310\n",
      "Val Loss: 4.2703\n",
      "73.0% done\n",
      "Loss:     4.0310\n",
      "Val Loss: 4.2799\n",
      "74.0% done\n",
      "Loss:     4.0310\n",
      "Val Loss: 4.2680\n",
      "75.0% done\n",
      "Loss:     4.0311\n",
      "Val Loss: 4.2715\n",
      "76.0% done\n",
      "Loss:     4.0310\n",
      "Val Loss: 4.2699\n",
      "77.0% done\n",
      "Loss:     4.0310\n",
      "Val Loss: 4.2673\n",
      "78.0% done\n",
      "Loss:     4.0309\n",
      "Val Loss: 4.2733\n",
      "79.0% done\n",
      "Loss:     4.0309\n",
      "Val Loss: 4.2691\n",
      "80.0% done\n",
      "Loss:     4.0309\n",
      "Val Loss: 4.2652\n",
      "81.0% done\n",
      "Loss:     4.0309\n",
      "Val Loss: 4.2719\n",
      "82.0% done\n",
      "Loss:     4.0309\n",
      "Val Loss: 4.2622\n",
      "83.0% done\n",
      "Loss:     4.0308\n",
      "Val Loss: 4.2686\n",
      "84.0% done\n",
      "Loss:     4.0309\n",
      "Val Loss: 4.2695\n",
      "85.0% done\n",
      "Loss:     4.0308\n",
      "Val Loss: 4.2687\n",
      "86.0% done\n",
      "Loss:     4.0308\n",
      "Val Loss: 4.2645\n",
      "87.0% done\n",
      "Loss:     4.0308\n",
      "Val Loss: 4.2638\n",
      "88.0% done\n",
      "Loss:     4.0308\n",
      "Val Loss: 4.2670\n",
      "89.0% done\n",
      "Loss:     4.0307\n",
      "Val Loss: 4.2642\n",
      "90.0% done\n",
      "Loss:     4.0308\n",
      "Val Loss: 4.2703\n",
      "91.0% done\n",
      "Loss:     4.0308\n",
      "Val Loss: 4.2610\n",
      "92.0% done\n",
      "Loss:     4.0307\n",
      "Val Loss: 4.2666\n",
      "93.0% done\n",
      "Loss:     4.0307\n",
      "Val Loss: 4.2640\n",
      "94.0% done\n",
      "Loss:     4.0306\n",
      "Val Loss: 4.2698\n",
      "95.0% done\n",
      "Loss:     4.0307\n",
      "Val Loss: 4.2651\n",
      "96.0% done\n",
      "Loss:     4.0306\n",
      "Val Loss: 4.2637\n",
      "97.0% done\n",
      "Loss:     4.0306\n",
      "Val Loss: 4.2689\n",
      "98.0% done\n",
      "Loss:     4.0307\n",
      "Val Loss: 4.2573\n",
      "99.0% done\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "model2 = ClassifierModel2().to(device)\n",
    "\n",
    "criterion2 = nn.CrossEntropyLoss()\n",
    "optimizer2 = optim.AdamW(model2.parameters(), lr=0.001, amsgrad=True)\n",
    "\n",
    "\n",
    "loss_list2 = []\n",
    "val_loss_list2 = []\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(25000):  # loop over the dataset multiple times\n",
    "\n",
    "    # zero the parameter gradients\n",
    "    optimizer2.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = model2(train_set)\n",
    "    loss2 = criterion2(outputs, train_answers)\n",
    "    \n",
    "    loss_list2.append(float(str(loss2).split(\"(\")[1].split(\",\")[0]))\n",
    "    \n",
    "    loss2.backward()\n",
    "    optimizer2.step()\n",
    "    \n",
    "    val_outputs = model2(val_set)\n",
    "    val_loss2 = criterion2(val_outputs, val_answers)\n",
    "    \n",
    "    val_loss_list2.append(float(str(val_loss2).split(\"(\")[1].split(\",\")[0]))\n",
    "    \n",
    "    # print statistics\n",
    "    if epoch % 250 == 0:\n",
    "        print(\"Loss:     \" + str(loss2).split(\"(\")[1].split(\",\")[0])\n",
    "        print(\"Val Loss: \" + str(val_loss2).split(\"(\")[1].split(\",\")[0])\n",
    "        print(str(epoch/250) + \"% done\")\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# Save initial training results\n",
    "\n",
    "torch.save(model2, '.\\\\models\\\\proper_vectors_wide_and_deep.1_save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21c86ef0c40>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list2)\n",
    "plt.plot(val_loss_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:     4.0307\n",
      "Val Loss: 4.2628\n",
      "0.0% done\n",
      "Loss:     4.0306\n",
      "Val Loss: 4.2590\n",
      "1.0% done\n",
      "Loss:     4.0306\n",
      "Val Loss: 4.2706\n",
      "2.0% done\n",
      "Loss:     4.0307\n",
      "Val Loss: 4.2641\n",
      "3.0% done\n",
      "Loss:     4.0308\n",
      "Val Loss: 4.2605\n",
      "4.0% done\n",
      "Loss:     4.0307\n",
      "Val Loss: 4.2648\n",
      "5.0% done\n",
      "Loss:     4.0306\n",
      "Val Loss: 4.2632\n",
      "6.0% done\n",
      "Loss:     4.0307\n",
      "Val Loss: 4.2601\n",
      "7.0% done\n",
      "Loss:     4.0307\n",
      "Val Loss: 4.2693\n",
      "8.0% done\n",
      "Loss:     4.0306\n",
      "Val Loss: 4.2588\n",
      "9.0% done\n",
      "Loss:     4.0306\n",
      "Val Loss: 4.2638\n",
      "10.0% done\n",
      "Loss:     4.0307\n",
      "Val Loss: 4.2619\n",
      "11.0% done\n",
      "Loss:     4.0307\n",
      "Val Loss: 4.2650\n",
      "12.0% done\n",
      "Loss:     4.0307\n",
      "Val Loss: 4.2605\n",
      "13.0% done\n",
      "Loss:     4.0306\n",
      "Val Loss: 4.2672\n",
      "14.0% done\n",
      "Loss:     4.0307\n",
      "Val Loss: 4.2561\n",
      "15.0% done\n",
      "Loss:     4.0306\n",
      "Val Loss: 4.2605\n",
      "16.0% done\n",
      "Loss:     4.0306\n",
      "Val Loss: 4.2631\n",
      "17.0% done\n",
      "Loss:     4.0306\n",
      "Val Loss: 4.2652\n",
      "18.0% done\n",
      "Loss:     4.0306\n",
      "Val Loss: 4.2588\n",
      "19.0% done\n",
      "Loss:     4.0306\n",
      "Val Loss: 4.2615\n",
      "20.0% done\n",
      "Loss:     4.0306\n",
      "Val Loss: 4.2639\n",
      "21.0% done\n",
      "Loss:     4.0306\n",
      "Val Loss: 4.2697\n",
      "22.0% done\n",
      "Loss:     4.0306\n",
      "Val Loss: 4.2624\n",
      "23.0% done\n",
      "Loss:     4.0306\n",
      "Val Loss: 4.2571\n",
      "24.0% done\n",
      "Loss:     4.0306\n",
      "Val Loss: 4.2596\n",
      "25.0% done\n",
      "Loss:     4.0305\n",
      "Val Loss: 4.2599\n",
      "26.0% done\n",
      "Loss:     4.0305\n",
      "Val Loss: 4.2705\n",
      "27.0% done\n",
      "Loss:     4.0305\n",
      "Val Loss: 4.2625\n",
      "28.0% done\n",
      "Loss:     4.0305\n",
      "Val Loss: 4.2679\n",
      "29.0% done\n",
      "Loss:     4.0305\n",
      "Val Loss: 4.2616\n",
      "30.0% done\n",
      "Loss:     4.0306\n",
      "Val Loss: 4.2639\n",
      "31.0% done\n",
      "Loss:     4.0305\n",
      "Val Loss: 4.2631\n",
      "32.0% done\n",
      "Loss:     4.0305\n",
      "Val Loss: 4.2641\n",
      "33.0% done\n",
      "Loss:     4.0305\n",
      "Val Loss: 4.2635\n",
      "34.0% done\n",
      "Loss:     4.0304\n",
      "Val Loss: 4.2634\n",
      "35.0% done\n",
      "Loss:     4.0304\n",
      "Val Loss: 4.2648\n",
      "36.0% done\n",
      "Loss:     4.0304\n",
      "Val Loss: 4.2585\n",
      "37.0% done\n",
      "Loss:     4.0304\n",
      "Val Loss: 4.2688\n",
      "38.0% done\n",
      "Loss:     4.0303\n",
      "Val Loss: 4.2585\n",
      "39.0% done\n",
      "Loss:     4.0303\n",
      "Val Loss: 4.2601\n",
      "40.0% done\n",
      "Loss:     4.0303\n",
      "Val Loss: 4.2622\n",
      "41.0% done\n",
      "Loss:     4.0303\n",
      "Val Loss: 4.2570\n",
      "42.0% done\n",
      "Loss:     4.0303\n",
      "Val Loss: 4.2565\n",
      "43.0% done\n",
      "Loss:     4.0302\n",
      "Val Loss: 4.2699\n",
      "44.0% done\n",
      "Loss:     4.0302\n",
      "Val Loss: 4.2572\n",
      "45.0% done\n",
      "Loss:     4.0302\n",
      "Val Loss: 4.2640\n",
      "46.0% done\n",
      "Loss:     4.0302\n",
      "Val Loss: 4.2616\n",
      "47.0% done\n",
      "Loss:     4.0302\n",
      "Val Loss: 4.2628\n",
      "48.0% done\n",
      "Loss:     4.0303\n",
      "Val Loss: 4.2612\n",
      "49.0% done\n",
      "Loss:     4.0303\n",
      "Val Loss: 4.2641\n",
      "50.0% done\n",
      "Loss:     4.0302\n",
      "Val Loss: 4.2671\n",
      "51.0% done\n",
      "Loss:     4.0302\n",
      "Val Loss: 4.2583\n",
      "52.0% done\n",
      "Loss:     4.0302\n",
      "Val Loss: 4.2630\n",
      "53.0% done\n",
      "Loss:     4.0302\n",
      "Val Loss: 4.2532\n",
      "54.0% done\n",
      "Loss:     4.0302\n",
      "Val Loss: 4.2642\n",
      "55.0% done\n",
      "Loss:     4.0301\n",
      "Val Loss: 4.2586\n",
      "56.0% done\n",
      "Loss:     4.0302\n",
      "Val Loss: 4.2620\n",
      "57.0% done\n",
      "Loss:     4.0301\n",
      "Val Loss: 4.2639\n",
      "58.0% done\n",
      "Loss:     4.0301\n",
      "Val Loss: 4.2572\n",
      "59.0% done\n",
      "Loss:     4.0301\n",
      "Val Loss: 4.2628\n",
      "60.0% done\n",
      "Loss:     4.0301\n",
      "Val Loss: 4.2642\n",
      "61.0% done\n",
      "Loss:     4.0301\n",
      "Val Loss: 4.2582\n",
      "62.0% done\n",
      "Loss:     4.0301\n",
      "Val Loss: 4.2673\n",
      "63.0% done\n",
      "Loss:     4.0301\n",
      "Val Loss: 4.2567\n",
      "64.0% done\n",
      "Loss:     4.0301\n",
      "Val Loss: 4.2615\n",
      "65.0% done\n",
      "Loss:     4.0301\n",
      "Val Loss: 4.2625\n",
      "66.0% done\n",
      "Loss:     4.0301\n",
      "Val Loss: 4.2569\n",
      "67.0% done\n",
      "Loss:     4.0300\n",
      "Val Loss: 4.2618\n",
      "68.0% done\n",
      "Loss:     4.0300\n",
      "Val Loss: 4.2615\n",
      "69.0% done\n",
      "Loss:     4.0300\n",
      "Val Loss: 4.2556\n",
      "70.0% done\n",
      "Loss:     4.0299\n",
      "Val Loss: 4.2610\n",
      "71.0% done\n",
      "Loss:     4.0298\n",
      "Val Loss: 4.2633\n",
      "72.0% done\n",
      "Loss:     4.0299\n",
      "Val Loss: 4.2569\n",
      "73.0% done\n",
      "Loss:     4.0299\n",
      "Val Loss: 4.2581\n",
      "74.0% done\n",
      "Loss:     4.0299\n",
      "Val Loss: 4.2599\n",
      "75.0% done\n",
      "Loss:     4.0299\n",
      "Val Loss: 4.2593\n",
      "76.0% done\n",
      "Loss:     4.0298\n",
      "Val Loss: 4.2651\n",
      "77.0% done\n",
      "Loss:     4.0299\n",
      "Val Loss: 4.2678\n",
      "78.0% done\n",
      "Loss:     4.0298\n",
      "Val Loss: 4.2601\n",
      "79.0% done\n",
      "Loss:     4.0299\n",
      "Val Loss: 4.2619\n",
      "80.0% done\n",
      "Loss:     4.0298\n",
      "Val Loss: 4.2634\n",
      "81.0% done\n",
      "Loss:     4.0299\n",
      "Val Loss: 4.2530\n",
      "82.0% done\n",
      "Loss:     4.0298\n",
      "Val Loss: 4.2629\n",
      "83.0% done\n",
      "Loss:     4.0299\n",
      "Val Loss: 4.2526\n",
      "84.0% done\n",
      "Loss:     4.0299\n",
      "Val Loss: 4.2621\n",
      "85.0% done\n",
      "Loss:     4.0299\n",
      "Val Loss: 4.2578\n",
      "86.0% done\n",
      "Loss:     4.0299\n",
      "Val Loss: 4.2580\n",
      "87.0% done\n",
      "Loss:     4.0299\n",
      "Val Loss: 4.2533\n",
      "88.0% done\n",
      "Loss:     4.0298\n",
      "Val Loss: 4.2506\n",
      "89.0% done\n",
      "Loss:     4.0298\n",
      "Val Loss: 4.2579\n",
      "90.0% done\n",
      "Loss:     4.0299\n",
      "Val Loss: 4.2576\n",
      "91.0% done\n",
      "Loss:     4.0298\n",
      "Val Loss: 4.2532\n",
      "92.0% done\n",
      "Loss:     4.0299\n",
      "Val Loss: 4.2607\n",
      "93.0% done\n",
      "Loss:     4.0299\n",
      "Val Loss: 4.2616\n",
      "94.0% done\n",
      "Loss:     4.0298\n",
      "Val Loss: 4.2589\n",
      "95.0% done\n",
      "Loss:     4.0298\n",
      "Val Loss: 4.2522\n",
      "96.0% done\n",
      "Loss:     4.0298\n",
      "Val Loss: 4.2678\n",
      "97.0% done\n",
      "Loss:     4.0298\n",
      "Val Loss: 4.2518\n",
      "98.0% done\n",
      "Loss:     4.0299\n",
      "Val Loss: 4.2574\n",
      "99.0% done\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(25000):  # loop over the dataset multiple times\n",
    "\n",
    "    # zero the parameter gradients\n",
    "    optimizer2.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = model2(train_set)\n",
    "    loss2 = criterion2(outputs, train_answers)\n",
    "    \n",
    "    loss_list2.append(float(str(loss2).split(\"(\")[1].split(\",\")[0]))\n",
    "    \n",
    "    loss2.backward()\n",
    "    optimizer2.step()\n",
    "    \n",
    "    val_outputs = model2(val_set)\n",
    "    val_loss2 = criterion2(val_outputs, val_answers)\n",
    "    \n",
    "    val_loss_list2.append(float(str(val_loss2).split(\"(\")[1].split(\",\")[0]))\n",
    "    \n",
    "    # print statistics\n",
    "    if epoch % 250 == 0:\n",
    "        print(\"Loss:     \" + str(loss2).split(\"(\")[1].split(\",\")[0])\n",
    "        print(\"Val Loss: \" + str(val_loss2).split(\"(\")[1].split(\",\")[0])\n",
    "        print(str(epoch/250) + \"% done\")\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21ccd140730>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list2)\n",
    "plt.plot(val_loss_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent correct (Accuracy): 0.6725454545454546\n"
     ]
    }
   ],
   "source": [
    "outputs = model2(test_set)\n",
    "\n",
    "maxes = np.argmax(outputs.to('cpu').detach().numpy(), axis = 1)\n",
    "correct_guesses = [maxes[i] == test_answer[i] for i in range(len(maxes))]\n",
    "\n",
    "print(\"Percent correct (Accuracy): \" + str(correct_guesses.count(True)/len(correct_guesses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model2, '.\\\\models\\\\proper_vectors_wide_and_deep.2_save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
